# Configuration for 100% token removal experiment (CLOSED THINKING MODE)
# This experiment:
# 1. Loads previously sampled responses with thinking traces
# 2. Removes 100% of tokens from the thinking trace (all CoT content)
# 3. Leaves only opening and closing thinking tags: <think>\n</think>
# 4. Uses OpenRouter completions API to generate the final answer

# Model configuration
model:
  name: "deepseek/deepseek-r1"
  temperature: 0.6
  max_tokens: 16384
  top_p: 0.95
  timeout: 120

# OpenRouter configuration
openrouter:
  providers: ["DeepInfra"]

# Prompt formatting tokens
prompt_formatting:
  prefix_tokens: "<｜begin▁of▁sentence｜><｜User｜>"
  assistant_prefix: "<｜Assistant｜>"
  thinking_tag: "think"

# Experiment configuration
experiment:
  # Input: previously sampled responses
  input_responses_dir: "experiments/results/deepseek-r1/math500/samples"

  # Which prompts to process
  start_index: 0
  end_index: 2  # Process first 2 for testing 100% removal
  # Note: ALL responses per prompt will be processed

  # Token removal configuration
  percentage_to_remove: 1.0  # 100% - remove ALL CoT tokens

  # Thinking tag mode
  close_thinking_tag: true  # TRUE = close tag, only <think>\n</think> remains

  # Random seed for reproducibility
  seed: 42

  # Output configuration
  output_dir: "experiments/results/token_removal_100pct"
